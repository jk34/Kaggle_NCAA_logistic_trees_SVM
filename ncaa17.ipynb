{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the winners of the 2017 NCAA basketball tournament"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "-We use Seed, BPI and the regular season winning percentages of each team to predict the winner of each potential matchup\n",
    "\n",
    "-According to http://www.espn.com/mens-college-basketball/bpi, BPI is:\n",
    "\n",
    "    The College Basketball Power Index (BPI) is a measure of team strength that is meant to be the best predictor of performance going forward. BPI represents how many points above or below average a team is.\"\n",
    "\n",
    "-Full description of BPI is explained here: http://www.espn.com/mens-college-basketball/story/_/id/7561413/bpi-college-basketball-power-index-explained\n",
    "\n",
    "-The results are in \"predictions.csv\". Some of the predictions make intuitive sense as they match historical results. For example, the code below predicts\n",
    "2-seeded Duke to beat 15-seeded Troy with a 96% probability and 2-seeded Kentucky with a 98.8% probability to beat 15-seeded N Kentucky.\n",
    "This makes sense because ever since 1985, the 2-seeded teams have beaten the 15-seeded teams 93.75% out of all matchups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "I wanted to predict the winners of the 2017 NCAA basketball tournament because I have enjoyed watching the tournament in previous years\n",
    "and I also enjoy using Python programming for manipulating data, performing data analysis, and generating predictions on data sets\n",
    "\n",
    "I obtained my data from Kaggle: https://www.kaggle.com/c/march-machine-learning-mania-2017/data\n",
    "        \n",
    "\"RegularSeasonCompactResults.csv\" contains data for the winners and losers of each game in all the regular seasons from 1985 to 2017\n",
    "\n",
    "\"Teams.csv\" contains each team in NCAA basketball and their team ID value\n",
    "\n",
    "\"TourneyCompactResults.csv\" contains the results of each tournament game for the 1985 to 2016 tournaments\n",
    "\n",
    "\"TourneySeeds.csv\" contains the seeds for each team in the tournaments from 1985 to 2016\n",
    "\n",
    "I used some of the blog_utility.r code from https://statsguys.wordpress.com/2014/03/15/data-analytics-for-beginners-march-machine-learning-mania-part-ii/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "The CSV files provided by Kaggle are assumed to be already cleaned. I could perform further data exploration, but due to time constraints, I chose not to. I could have generated histograms and boxplots to look for noticeable typos and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "#### First need a function that returns a dataframe in a format containing TEAMID`, `TWPCT`, `SEED`, and `BPI` for each team in a given season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `TWPCT` is the regular season winning percentage, `SEED` is the seed in the tournament, and `BPI` is the BPI ranking for that team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ncaa17.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def team_metrics_by_season(seasonletter):\n",
    "    #get seeds for all teams in previous tournaments\n",
    "    tourneySeeds= pd.read_csv(\"tourney_seeds.csv\", sep=',') \n",
    " \n",
    "    #get seeds for all teams in 2017 tournament\n",
    "    tourneySeeds1= pd.read_csv(\"TourneySeeds2017BPI.csv\", sep=',') \n",
    "\n",
    "    #read in BPI2017.csv, which was generated from getBPI.r\n",
    "    #it contains the BPI rankings for each team in the 2017 tournament\n",
    "    BPI17= pd.read_csv(\"BPI2017.csv\", sep=',')\n",
    "\n",
    "    #modify names of certain teams to match their names in teams.csv\n",
    "    #for example, \"Wichita State\" from BPI2017.csv needs to be changed to \"Wichita St\" to\n",
    "    #match \"Wichita St\" in teams.csv\n",
    "    BPI17['Team'] = BPI17.Team.str.replace(r\"\\bState\\b\", \"St\")\n",
    "    BPI17.set_value(11, 'Team', \"St Mary's CA\")\n",
    "    BPI17.set_value(27, 'Team', \"Miami FL\")\n",
    "    BPI17.set_value(38, 'Team', \"VA Commonwealth\")\n",
    "    BPI17.set_value(44, 'Team', \"MTSU\")\n",
    "    BPI17.set_value(72, 'Team', \"ETSU\")\n",
    "    BPI17.set_value(74, 'Team', \"Monmouth NJ\")\n",
    "    BPI17.set_value(77, 'Team', \"Mississippi\")\n",
    "    BPI17.set_value(79, 'Team', \"FL Gulf Coast\")\n",
    "    BPI17.set_value(82, 'Team', \"NC State\")\n",
    "    BPI17.set_value(91, 'Team', \"Col Charleston\")\n",
    "    BPI17.set_value(203, 'Team', \"Mt St Mary's\")\n",
    "    BPI17.set_value(185, 'Team', \"S Dakota St\")\n",
    "    BPI17.set_value(150, 'Team', \"NC Central\")\n",
    "    BPI17.set_value(136, 'Team', \"Kent\")\n",
    "    BPI17.set_value(175, 'Team', \"N Kentucky\")\n",
    "    BPI17.set_value(177, 'Team', \"TX Southern\")\n",
    "\n",
    "    teamNames= pd.read_csv(\"teams.csv\", sep=',') \n",
    "\n",
    "    #merge teamNames, which contains the names and team_id of each team, with BPI17, which contains the BPI of each team\n",
    "    BPI2017= pd.merge(BPI17,teamNames, left_on='Team',right_on='team_name')\n",
    "\n",
    "    #get just the teams and their seeds for the 2017 tournament\n",
    "    tourneySeeds17 = tourneySeeds1[tourneySeeds1[\"season\"]==2017]\n",
    "\n",
    "    #merge to get the team name, team_id, seed, and BPI of each team in the 2017 tournament\n",
    "    tourneySeeds17F= pd.merge(tourneySeeds17,BPI2017, left_on='team',right_on='team_id')\n",
    "\n",
    "    #only need columns season, seed, team, BPI_y\n",
    "    tourneySeeds17F.drop(tourneySeeds17F.columns[[3,5,6,7]], axis=1, inplace=True)\n",
    "\n",
    "    #change \"BPI_y\" to \"BPI\"\n",
    "    tourneySeeds17F=tourneySeeds17F.rename(columns = {'BPI_y':'BPI'})\n",
    "\n",
    "    #append 2017 data to data containing seasons 1985-2014 (could also include seasons 2015-2016, but I figured the training set is already large enough)\n",
    "    tourneySeeds=tourneySeeds.append(pd.DataFrame(data=tourneySeeds17F))\n",
    "\n",
    "    #save this into csv file because it will later be loaded into submissionFile in test_frame_model\n",
    "    tourneySeeds.to_csv(\"tourney_seeds17.csv\", sep=',') \n",
    "\n",
    "    #load in the regular season data for seasons 1985-2014,2017\n",
    "    regSeason= pd.read_csv(\"regular_season_compact_results2017.csv\", sep=',')\n",
    "\n",
    "    #convert all column names to lower-case\n",
    "    regSeason.columns = map(str.lower, regSeason.columns)\n",
    "\n",
    "    #Selecting the season, seed, team, and BPI for a given season.\n",
    "    #Ex: To get the data for the 2010 season, where seasonletter=2010\n",
    "    season_seeds = tourneySeeds[tourneySeeds.season == seasonletter] \n",
    "\n",
    "    #sort values by the team id in the \"team\" column\n",
    "    playoff_teams = season_seeds.sort_values(['team'], ascending=[1])\n",
    "\n",
    "\n",
    "    playoff_seeds = season_seeds\n",
    "\n",
    "    #Selecting the regular season statistics for a given season\n",
    "    season = regSeason[regSeason.season == seasonletter] \n",
    "\n",
    "    #Count the number of wins for each team in a given regular season\n",
    "    win_freq_table = season.wteam\n",
    "    wins_count = win_freq_table.value_counts()\n",
    "    wins_by_team = pd.DataFrame(data= {'team': wins_count.index.values, 'wins': wins_count.values} )\n",
    "\n",
    "    #Losses by team\n",
    "    loss_freq_table = season.lteam\n",
    "    loss_count = loss_freq_table.value_counts()\n",
    "    loss_by_team = pd.DataFrame(data= {'team': loss_count.index.values, 'loss': loss_count.values} )\n",
    "\n",
    "    #Total Win Percentage for each team in a given regular season\n",
    "    games_df = wins_by_team.merge(loss_by_team, on='team')\n",
    "    games_df['games'] = games_df['wins'] + games_df['loss']\n",
    "    games_df['winpct'] = games_df['wins']/games_df['games']\n",
    "    total_winpct_by_team = games_df.loc[:,['team','winpct']]\n",
    "\n",
    "    #extract numerical value of seeds for each playoff team\n",
    "    #extract numerical value of seed. For example, for seed \"W01\", get just \"1\"\n",
    "    team_seeds = playoff_seeds['seed'].str.extract('(\\d+)').astype(int)\n",
    "    playoff_seeds.seed = team_seeds\n",
    "    playoff_teams['seed'] = playoff_seeds.seed\n",
    " \n",
    "    #combining columns together\n",
    "    #to get season, seed, team, BPI, and winpct for each team in the tournament\n",
    "    team_metrics = total_winpct_by_team.merge(playoff_teams, on='team')\n",
    "\n",
    "    #only keep columns teamID, TW_PCT, A_SEED, A_BPI\n",
    "    team_metrics = team_metrics.loc[:,['team','winpct','seed','BPI']]\n",
    "    team_metrics.columns = ['TEAMID', 'A_TWPCT', 'A_SEED','A_BPI']\n",
    "    return team_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dataframe for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To use seasons 2008-2012 as the full training set, merge the train_frame_model dataframes for seasons 2008-2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_frame_model(seasonletter):\n",
    "    #get results of each game in previous tournaments\n",
    "    #the season, winning team's id (wteam), and losing team's id (lteam)\n",
    "    tourneyRes= pd.read_csv(\"tourney_compact_results.csv\", sep=',') \n",
    "\n",
    "    #get results for a given tournament season\n",
    "    season_matches = tourneyRes[tourneyRes.season == seasonletter]\n",
    "\n",
    "    #get the id, winning percentage, seed, and BPI for each team in a given season\n",
    "    teamMetrics = team_metrics_by_season(seasonletter)\n",
    "\n",
    "    #each entry in \"team\" looks something like \"2010_1115_1457\"\n",
    "    #In that example, seasonletter=2010, wteam=1115, lteam=1457\n",
    "    #this format is necessary because Kaggle requires a similar format when accepting the predictions in a csv file\n",
    "    team = pd.Series()\n",
    "    str_seasonletter = str(seasonletter)\n",
    "    team = str_seasonletter + \"_\" + season_matches.wteam.astype(str) + '_' + season_matches.lteam.astype(str)\n",
    "    \n",
    "    #loc returns the indices.\n",
    "    #if ixs = season_matches['wteam'] > season_matches['lteam'], then\n",
    "    #season_matches[ixs] returns the indices where season_matches['wteam'] > season_matches['lteam']\n",
    "    ixs = season_matches['wteam'] > season_matches['lteam']\n",
    "    team[ixs] = str_seasonletter + \"_\" + season_matches.loc[ixs,'lteam'].astype(str) + '_' + season_matches.loc[ixs,'wteam'].astype(str)\n",
    "    result = pd.Series(np.ones(ixs.shape))\n",
    "    result= 1-ixs\n",
    "    #result is initialized to all 1's\n",
    "    #when ixs is satisfied, result is set to 0 because 1-1=0, where ixs=1 because boolean=True\n",
    "    #else, result is 1-0=1\n",
    "\n",
    "    #want to generate a dataframe containing the matchups and the win column\n",
    "    #result will look like:\n",
    "    #Matchup           Win\n",
    "    #2010_1124_1181    0\n",
    "    #2010_1277_1397    1\n",
    "    #The team with the lower id value is placed before the team with the higher id\n",
    "    #Win=0 means the 1st team lost. So team 1124 lost to team 1181 in the 2010 season\n",
    "    #Win=1 means the 1st team won. So team 1277 beat team 1397 in the 2010 season\n",
    "    list_series = [team,result]\n",
    "    labels = range(len(list_series))\n",
    "    model_data_frame  = pd.concat(list_series, levels=labels,axis=1)\n",
    "    model_data_frame.columns = ['Matchup', 'Win']\n",
    "\n",
    "\n",
    "    #will create a dataframe containing Matchup, Win (1 or 0), HomeID, AwayID, and the Winpct/Seed/BPI for the HomeID and AwayID\n",
    "    #for simplicity, HomeID refers to the team with the lower team_id value\n",
    "    #it is not related to the seeds of the teams in each matchup\n",
    "    \n",
    "    #For example, for the entry\n",
    "    #2010_1115_1457  1  1115  1457 0.531250 16 220.0 0.566667 16 223.0\n",
    "    #In the 2010 season, team with id=1115 is the \"home\" team and team with id=\"1457\" is the \"away\" team\n",
    "    #the home team won because Win=1, it had a .531 Winpct in the regular season, it was a 16 seed, and its BPI was 222. The away team had a .566 Winpct, 16 seed, and BPI=223\n",
    "    teamMetrics_away = teamMetrics\n",
    "    teamMetrics_away.columns = ['TEAMID', 'B_TWPCT', 'B_SEED','B_BPI']\n",
    "\n",
    "    df2 = model_data_frame['Matchup'].str.split('_', expand=True)\n",
    "    #convert to numbers\n",
    "    df2 = df2.astype(int)\n",
    "    df2.columns = ['Season','HomeID', 'AwayID']\n",
    "    df2 = df2.loc[:,['HomeID', 'AwayID']]\n",
    "    model_data_frame = model_data_frame.join(df2)\n",
    "\n",
    "    model_data_frame = pd.merge(model_data_frame, teamMetrics, how='left', left_on='HomeID', right_on='TEAMID')\n",
    "    model_data_frame = model_data_frame.drop('TEAMID', 1)\n",
    "    model_data_frame.columns = ['Matchup','Win','HomeID', 'AwayID','A_TWPCT', 'A_SEED','A_BPI']\n",
    "\n",
    "    model_data_frame = pd.merge(model_data_frame, teamMetrics_away, how='left', left_on='AwayID', right_on='TEAMID')\n",
    "    model_data_frame = model_data_frame.drop('TEAMID', 1)\n",
    "\n",
    "    return model_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dataframe for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_frame_model(seasonletter):\n",
    "    #similar to train_frame_model, but it generates a dataframe for the test set\n",
    "    model_data_frame = submissionFile(seasonletter)\n",
    "\n",
    "    teamMetrics = team_metrics_by_season(seasonletter) \n",
    "    teamMetrics_away = teamMetrics\n",
    "    teamMetrics_away.columns = ['TEAMID', 'B_TWPCT', 'B_SEED','B_BPI']\n",
    "\n",
    "    df2 = model_data_frame['Matchup'].str.split('_', expand=True)\n",
    "    #convert to numbers\n",
    "    df2 = df2.astype(int)\n",
    "    df2.columns = ['Season','HomeID', 'AwayID']\n",
    "    df2 = df2.loc[:,['HomeID', 'AwayID']]\n",
    "    model_data_frame = model_data_frame.join(df2)\n",
    "\n",
    "    model_data_frame = pd.merge(model_data_frame, teamMetrics, how='left', left_on='HomeID', right_on='TEAMID')\n",
    "    model_data_frame = model_data_frame.drop('TEAMID', 1)\n",
    "    model_data_frame.columns = ['Matchup','Win','HomeID', 'AwayID','A_TWPCT', 'A_SEED','A_BPI']\n",
    "\n",
    "    model_data_frame = pd.merge(model_data_frame, teamMetrics_away, how='left', left_on='AwayID', right_on='TEAMID')\n",
    "    model_data_frame = model_data_frame.drop('TEAMID', 1)\n",
    "    #print \"MODEL DATA FRAME\", model_data_frame\n",
    "    return model_data_frame\n",
    "\n",
    "\n",
    "def submissionFile(seasonletter):\n",
    "    #Selecting and sorting the playoff teamIDs least to greatest for season A\n",
    "    tourneySeeds= pd.read_csv(\"tourney_seeds17.csv\", sep=',')\n",
    "    season_seeds = tourneySeeds[tourneySeeds.season == seasonletter] \n",
    "    playoffTeams = season_seeds['team']\n",
    "    playoffTeams = playoffTeams.sort_values(ascending=[1])\n",
    "    numTeams = len(playoffTeams.index)\n",
    "    str_seasonletter = str(seasonletter)\n",
    "    idcol = pd.Series(str_seasonletter+ \"_\" + \"_\".join([str(a),str(b)]) for a,b in combinations(playoffTeams,2))\n",
    "    form = idcol.to_frame()\n",
    "    form.columns=['Matchup']\n",
    "    form['result'] = np.NaN\n",
    "\n",
    "    return form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Logistic Regression to generate predictions for the 2017 season using 2008-2012 seasons as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:101: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "/home/jerry/.local/lib/python3.5/site-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    #Train model on training set (for example, using seasons 2008-2012)\n",
    "    trainData = pd.DataFrame()\n",
    "    for i in range(2008,2013): #from 2008 to 2013-1, so from 2008 to 2012\n",
    "        x = train_frame_model(i)\n",
    "        trainData  = pd.concat([trainData, x], axis=0)\n",
    "        #axis=0 means we concat x BELOW trainData. Axis=1, means we append similar to cbind\n",
    "\n",
    "    #use upcoming tournament (season 2017) as test set\n",
    "    testData = pd.DataFrame()\n",
    "    for i in range(2017,2018):\n",
    "        y = test_frame_model(i)\n",
    "        testData  = pd.concat([testData, y], axis=0)\n",
    "\n",
    "\n",
    "    '''Use Logistic Regression\n",
    "    I just used C=.01, but I probably should use GridSearchCV and 10-fold CV to find a better value for C\n",
    "    I also could have compared the best score from Logistic Regression with other models, such as Gradient Boosting, K-Nearest Neighbors, SVM, etc\n",
    "    But I just wanted to generate predictions quickly since the tournament is coming up soon'''\n",
    "\n",
    "    #predictions will be generated in predictions.csv\n",
    "    #each row in predictions.csv contains the probability of each team winning in a potential matchup\n",
    "    #For example, for the row\n",
    "    #1112 1116 .636\n",
    "    #That means teamid=1112 has a .636 chance to beat teamid=1116\n",
    "\n",
    "    model = LogisticRegression(C=.01)\n",
    "    features=['A_TWPCT','A_SEED','A_BPI','B_TWPCT','B_SEED','B_BPI']\n",
    "    model.fit(trainData[features], trainData['Win'])\n",
    "    \n",
    "    predicted = np.array(model.predict_proba(testData[features]))\n",
    "    predicted = pd.DataFrame(predicted)\n",
    "    predicted.columns=['Win','Loss']\n",
    "    \n",
    "    subfile  = pd.concat([testData.Matchup, predicted.Loss], axis=1)\n",
    "    subfile.columns=['id', 'pred']\n",
    "\n",
    "    subfile1  = pd.concat([testData.HomeID, testData.AwayID, predicted.Loss], axis=1)\n",
    "    subfile1.to_csv(\"predictions.csv\", sep=',')   \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating bar plots of a few matchups showing the probabilities of each team winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate bar plots showing win probabilities of a few matchups using Seaborn\n",
    "    teamNames= pd.read_csv(\"teams.csv\", sep=',')\n",
    "    outNames= pd.merge(subfile1, teamNames,left_on='HomeID',right_on='team_id')\n",
    "    outNames= pd.merge(outNames, teamNames,left_on='AwayID',right_on='team_id')\n",
    "    outNames.drop(outNames.columns[[0,1,3,5]], axis=1, inplace=True)\n",
    "\n",
    "    #change \"BPI_y\" to \"BPI\"\n",
    "    outNames = outNames.rename(columns = {'team_name_x':'TeamA', 'team_name_y':'TeamB', 'Loss':'WinProb'})\n",
    "    #cols = outNames.columns.tolist()\n",
    "    #cols = cols[-1] + cols[:-1]\n",
    "    #outNames = outNames[cols]\n",
    "    outNames = outNames[['TeamA', 'TeamB', 'WinProb']]\n",
    "    outNames.to_csv(\"predictions1.csv\", sep=',')   \n",
    "\n",
    "    #generate plots\n",
    "    teamlst=[]\n",
    "    winlst=[]\n",
    "\n",
    "    for index, row in outNames.iterrows():\n",
    "        if (row[0]==\"Butler\" and row[1]==\"Winthrop\") or (row[1]==\"Butler\" and row[0]==\"Winthrop\"):\n",
    "            teamlst.append(row[0])\n",
    "            teamlst.append(row[1])\n",
    "            winlst.append(round(100*row[2],1))\n",
    "            winlst.append(round(100*(1-row[2]),1))\n",
    "        elif (row[0]==\"Maryland\" and row[1]==\"Xavier\") or (row[1]==\"Maryland\" and row[0]==\"Xavier\"):\n",
    "            teamlst.append(row[0])\n",
    "            teamlst.append(row[1])\n",
    "            winlst.append(round(100*row[2],1))\n",
    "            winlst.append(round(100*(1-row[2]),1))\n",
    "        elif (row[0]==\"Kent\" and row[1]==\"UCLA\") or (row[1]==\"Kent\" and row[0]==\"UCLA\"):\n",
    "            teamlst.append(row[0])\n",
    "            teamlst.append(row[1])\n",
    "            winlst.append(round(100*row[2],1))\n",
    "            winlst.append(round(100*(1-row[2]),1))\n",
    "        elif (row[0]==\"Creighton\" and row[1]==\"Rhode Island\") or (row[1]==\"Creighton\" and row[0]==\"Rhode Island\"):\n",
    "            teamlst.append(row[0])\n",
    "            teamlst.append(row[1])\n",
    "            winlst.append(round(100*row[2],1))\n",
    "            winlst.append(round(100*(1-row[2]),1))\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    from matplotlib import pyplot as plot\n",
    "\n",
    "    with PdfPages('winprobs.pdf') as pdf_pages:\n",
    "        fig,((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\n",
    "        list_of_axes = (ax1,ax2,ax3,ax4)\n",
    "        for i,j in zip(range(0,len(teamlst), 2),list_of_axes):\n",
    "            sns.barplot(teamlst[i:i+2], winlst[i:i+2],ax=j)\n",
    "            j.axes.set_title('Which team will win?', fontsize=14,color=\"b\",alpha=0.3)\n",
    "            j.set_ylabel(\"Win Probability (%)\",size = 12,color=\"r\",alpha=0.5)\n",
    "\n",
    "            for p in j.patches:\n",
    "                j.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "    \tpdf_pages.savefig()\n",
    "    \tplt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Here are a few results of the probabilities of teams winning in a matchup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"winprobs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The predictions should not taken to seriously. I generated the predictions using Logistic Regression\n",
    "and only tried C=.01. I probably should have used GridSearchCV and 10-fold CV to find a better value for C\n",
    "I also could have compared the best score from Logistic Regression with other models, such as Gradient Boosting, K-Nearest Neighbors, SVM, etc\n",
    "But I just wanted to generate predictions quickly since the tournament is coming up soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
